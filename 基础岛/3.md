# llamaindex+Internlm2 RAG实践
———————————————————————————————————————————————————————————————
## 将分为以下几个部分来介绍，如何使用 LlamaIndex 来部署 InternLM2 1.8B
### 前置知识
### 环境、模型准备
### LlamaIndex HuggingFaceLLM
### LlamaIndex RAG
———————————————————————————————————————————————————————————————
## 前置知识
正式介绍检索增强生成（Retrieval Augmented Generation，RAG）技术以前，大家不妨想想为什么会出现这样一个技术。 给模型注入新知识的方式，可以简单分为两种方式，一种是内部的，即更新模型的权重，另一个就是外部的方式，给模型注入格外的上下文或者说外部信息，不改变它的的权重。 第一种方式，改变了模型的权重即进行模型训练，这是一件代价比较大的事情，大语言模型具体的训练过程，可以参考InternLM2技术报告。第二种方式，并不改变模型的权重，只是给模型引入格外的信息。类比人类编程的过程，第一种方式相当于你记住了某个函数的用法，第二种方式相当于你阅读函数文档然后短暂的记住了某个函数的用法。
![image](https://github.com/user-attachments/assets/8c49f74e-a8db-4715-b8ac-2c5359d06201)
对比两种注入知识方式，第二种更容易实现。RAG正是这种方式。它能够让基础模型实现非参数知识更新，无需训练就可以掌握新领域的知识。本次课程选用了LlamaIndex框架。LlamaIndex 是一个上下文增强的 LLM 框架，旨在通过将其与特定上下文数据集集成，增强大型语言模型（LLMs）的能力。它允许您构建应用程序，既利用 LLMs 的优势，又融入您的私有或领域特定信息。
## 环境、模型准备
### 配置环境
![image](https://github.com/user-attachments/assets/af77c06e-1f41-4dee-9f68-3387d8c16b83)

### 模型的初始运行结果

![image](https://github.com/user-attachments/assets/f516fb21-d39f-4c9e-b416-e7119210110a)
## LlamaIndex RAG
### 安装词向量依赖
conda activate llamaindex

pip install llama-index-embeddings-huggingface==0.2.0 llama-index-embeddings-instructor==0.1.3
### 克隆一个知识库
cd ~/llamaindex_demo

mkdir data

cd data

git clone https://github.com/InternLM/xtuner.git

mv xtuner/README_zh-CN.md ./
### 转换为词向量库
![image](https://github.com/user-attachments/assets/6ebfd20c-64d2-4d89-9c77-d39f147f6156)

### 进行RAG之后的输出结果

![image](https://github.com/user-attachments/assets/424a35bd-6b23-4086-b2a2-ed944f54f8d6)
